# 基础问题
## 什么是Redis？
  基于键值对的NoSql数据库
  数据存放在内存中，比访问磁盘要快的多，达到微妙级相应

  ### 和 Mysql的区别？
  Mysql 是 关系型数据库，把行和列保存在磁盘上
  Redis 是非关系型数据库，把键值对保存在内存上
 

  ### 部署过Redis吗？
   在生产环境中部署过单机版，编译安装后编辑Redis.conf文件，开启远程访问和限制内存，设置内存过期淘汰策略
   ``` text
   bind 0.0.0.0
   maxmemory-policy allkeys-lru  //内存淘汰策略
   requirepass password 
   appendonly yes //AOF持久化
   ```

  ### Redis 高可用方案部署
  1. 部署过哨兵机制，这是一个相对成熟的方案，生产环境部署的一主两从的 Redis实例，在加上三个 Sentinel 节点监控
   Sentinel配置了故障转移的判定条件和超时阈值

   主节点配置 ： port 6379   appendonly yes   
   从节点配置： replicaof 192.168.245.128 6379 2
   哨兵节点： sentinel monitor mymaster 192.168.245.128.245.128 //监控mymaster 节点
              sentinel failover-timeout mymaster 60000 //故障转移超时时间
              sentinel down-after-milliseconds  mymaster 5000  //主观判定Mymaster 节点下线时间，超过5000ms没回复就是下线
              sentinel  auth-pass mymaster  "password"  //设置Master 节点密码（如果master有密码）
              sentinel  parallel-syncs mymaster 1   // 主节点故障后多少个从节点可以向新的主节点发起同步

   **主节点故障后，Sentinel可以协商新的主节点，大概10-15秒**
   
  2. 部署过Redis Cluster (集群模式) 
      大型项目部署过，数据量增长很快，需要水平扩展。部署了6个主节点，每个主节点配一个从节点，形成了3主3从 的初始集群
       cluster 需要配置节点间通信，分片映射
            
            创建6个节点目录 mkdir 7000 7001 7002 7003 7004 7005 
            创建通用配置文件 Redis-cluster.conf :
                       # 开启后台运行
                       daemonize yes
                       # 监听所有地址
                       bind 0.0.0.0
                       # 禁用保护模式（生产环境推荐配置强密码）
                       protected-mode no 
                       # 设置为日志文件路径
                       logfile "Redis.log"
                       
                       # **Redis Cluster 关键配置**
                       # 开启集群模式
                       cluster-enabled yes
                       # 集群配置文件，由 Redis 自动维护，记录集群状态
                       cluster-config-file nodes.conf
                       # 节点失联时间，超过这个时间被认为是故障
                       cluster-node-timeout 15000 
                       # 开启 AOF 持久化
                       appendonly yes
                       
                       # **占位符：启动时替换为实际值**
                       # port 7000
                       # dir /path/to/Redis-cluster/7000 
       
         节点配置： 7000.conf

                       # ... (其他通用配置不变)
                       port 7000
                       dir /path/to/Redis-cluster/7000

         使用Redis-cli 创建集群：
                      Redis-cli --cluster  create \
                        127.0.0.1:7000 127.0.0.1:7001  127.0.0.1:7002 \
                        127.0.0.1:7003 127.0.0.1:7004  127.0.0.1:7005  \
                        --cluster-replicas 1

   3. Cluster 的优势是数据自动分片，可以通过增加节点来扩展容量

      轻量应用可以主从复制 手动故障转移，主写从读 
                    # 1. 取消从节点身份
                    Redis-cli -h  《slave-ip》 slaveof no one    
                    # 2. 将其他从节点指向新的主节点
                    Redis-cli -h 《other-slave-ip》 slaveof 《new-master-ip》 《port》     

   ### 用过那些除了Redis的缓存数据库

   Guava Cache 和 Caffeine 作为本地缓存 ， 前者小规模缓存，后者支持更多高级特性，性能更好

   Caffeine 常作为二级缓存使用，减小Redis的压力


   ### Redis 可以用来做什么？
  
   Redis可以用来做缓存，把高频的访问数据放到Redis里，设置过期时间保证一致性，减轻数据库的压力

   Redis 的Zset 可以用来做排行榜 ，score字段排序 取前N个元素

   SETNX 或 Redisson 可以做分布式锁，设置有效期

  ### Redis 做缓存要考虑那些问题？
   缓存设计问题：缓存穿透，缓存击穿，缓存雪崩
   [[缓存使用策略]] 
   
   业务问题：数据一致性(修改数据库后缓存同步)，缓存粒度(缓存复杂对象还是字段)[]()
             

 ##  Redis 有那些数据类型？
   字符串，列表，哈希，集合，有序集合(基本)
   BitMap,HyperLogLog ,GEO (扩展)   

 ### 详细介绍？
  字符串是最基本的数据类型，存储文本，数字，二进制数据，容量512MB
  列表是有序的元素集合，从头部或尾部插入，适合消息队列或任务列表
  哈希是键值对集合，存储对象
  集合是无需不重复的，支持交差运算，查询效率O(1)。适合去重，标签，共同好友等场景
  有序集合元素按分数排序，适合排行榜和优先级队列
  BitMap把一组二进制数紧凑存储在连续内存中，每一位代表一个对象的状态。可以代表用户的某种状态
  HyperLogLog 基于基数统计的概率性数据结构，统计不重复元素的个数。
> HyperLogLog基于LOGLOG算法，每个元素哈希成二进制串，取前14位分组，放入16384个桶中，记录每组最大的前导0数量
> 用近似公式推算基数

  GEO存储和查询地理位置信息，可以计算两点距离，半径内的其他元素。使用附近查找，是否进入范围
  
 ### 为什么用Hash存储对象？
  用String需要取出整个对象序列化对象，无法局部更新
  Hash可以只取其中一个字段

## 为什么Redis很快？
  1. 内存读写快于磁盘
  2. IO多路复用的事件驱动模型处理请求和执行命令
  3. 对底层数据结构优化
> Redis IO多路复用技术在一个单线程下可以持续监听上万个客户端的连接
> 把请求压入队列，交给事件分派器，分派其交给对应的处理器

 **Redis 6 引入多线程机制**：
  6之前连接建立，请求读取，发送响应，执行命令都在主线程中串行执行。
  性能瓶颈是网络IO和内存操作,串行网络IO会占用时间片
  6之后把网络IO和执行命令分开，交给线程池来做,利用的多核CPU的性能
  

##  IO多路复用是什么？
  IO多路复用就是允许一个单线程同时监视多个文件描述符的技术，高效处理多并发连接而无需创建大量线程
 
  等待多个文件描述符就绪，对就绪的描述符进行操作
  
  主要的实现机制是select，poll，epoll，kqueue，IOCP

  ### 这几个的区别？
    select 单个进程监视的文件描述符有限，一般1024个，每次调用都要切换到内核态，性能差
    poll 没有最大文件描述符数量的限制，依然要切换到内核态，性能差
    epoll linux独有的，支持大规模并发连接，事件驱动模型，性能更高
    kqueue 是macos系统的，类似epoll，使用事件驱动模型
    IOCP windows系统，使用完整端口模型

  reids使用epoll，单线程下实现了高效的网络IO

  ### select epoll poll 原理
    select，poll把文件描述符传给内核，内核遍历判断哪些就绪
    select通过BitsMap传入内核，轮询所有的fd，通过调用poll函数查询是否有对应的事件，没有就把task加入fd
        传入对应的file等待队列，等待事件来临被唤醒。
    poll 改进连接数量上限问题，使用动态数组pollfd，仍然是线性遍历

  ==二者都是往内核拷贝再等内核处理完拷贝一份==
 
    epoll把监听的fd注册到红黑树，在内核事件触发时加入到readyList。 
  ==epoll支持事件驱动和边缘触发，epoll_wait时和用户共享空间，直接把数据拷贝到用户空间，高并发性能非常高==

 ## 为什么Redis早期使用单线程？
  1. 单线陈不用担心锁机制，便于开发维护
  2. Redis时IO密集型操作，主要受内存和网络io限制，单线陈可以避免上下文切换
  3. 单线程保证命令执行原子性

 ## Redis 6 使用多线程是为什么？
  用于处理网络IO
  执行命令依旧是单线程(主线程), 仅仅让IO 线程化，能够在高负载的情况下最大限度提升Redis响应
  
  ==使用步骤==:
  1. 主线程框框接客户端连接
  2. 连接分发给多io线程，主线程解析和执行命令
  3. 命令执行完成后，让多个IO线程返回给客户端

  当并发量很大时，主线程大部分事件都浪费在了大数据包的读取和写入，让其他线程把这个活儿干了，就可以同时处理很多个大数据包，
  大幅提高效率

## Redis 常用命令
 操作字符串“get,set,incr”,操作哈希"hset,hget,hgetAll",操作列表"Lpush,Lpop,LRange"，操作集合“sadd，sismember”，
 有序集合"zadd,zrange，zincrby",通用命令"expire，del，keys"
  
  ### 说说set命令
   set用于设置字符串key，支持过期事件和条件，用于设置缓存、实现分布式锁、存储session
    
  ### sadd 命令
   sadd <setName> val... 用于往set里放多个值，返回成功的个数。事件复杂度时O(n)
  ### incr 命令
   incr是原子命令，key不存在创建key赋值0并且+1，用于网站访问量或计数功能，生成全局唯一ID，库存减扣等等
## 单线陈QPS 有多少？
 每秒10w以上

# 持久化

 ## Redis持久化
  持久化的方式有 RDB 和AOF
  RDB创建时间点快照，AOF记录每个写操作命令
  ### RDB
   RDB在指定的事件间隔把数据保存到磁盘的RDB文件中，Redis重启会加载RDB
   save 命令(阻塞式),bgsave(fork子线程)
   ==触发方式==: 加入从节点，配置文件设置持久化参数 `save <seconds> <changes>`,没开AOF执行shutdown命令
  ### AOF
  AOF记录每个写操作命令，放到AOF文件，重启后执行这些文件
   AOF文件会不断记录导致过大，Redis会在这个时候剔除不必要的命令
  ==刷盘策略==: 将AOF的缓冲区写入文件有两个系统调用，write和fsync
  * write 将数据写入操作系统缓冲区
  * fsync 把OS缓冲区的数据刷新到磁盘
    `刷盘有三种策略：直接刷(always),定时刷(everysec),OS自己决定(no)`  
 ==AOF重写机制==: 应对AOF文件扩大的应对方式，对AOF压缩优化
  * 在Redis收到重写命令后，创子线程fork一份数据副本(内存副本)，遍历键值对并生成最少命令     
  * 使用了重写缓冲区策略，保证主线程可以一直处理客户端命令,主线程写操作将命令写到旧的AOF和重写缓冲区,子线程重写缓冲区和快照(优化)后 
  通知主线程,主线程替换旧的AOF
  ==AOF存储数据类型==: reids协议格式,`*` 开头，`$`后数据长度,然后是命令
 > [!NOTE]
 > AOF的整个过程就是把自己的活儿外包给人，让他按照这会儿的样子优化重干，然后你在把接下来的活儿接着分给他让他接着干
 > 缓冲区的意义就是咱俩的进度要同步，我容许你慢点但是要干完，干完就叫我给你派新活儿

## RDB 和 AOF 详解
### RDB 和 AOF 的优缺点
 RDB 让子线程fork全量数据的二进制快照,文件紧凑，恢复速度快,大规模数据迁移备份效果佳
 但是会丢掉增量数据
 
 AOF记录每次的修改记录，提供接近实时的数据备份，但是文件体积大恢复慢(重新执行)
 
### 业务选择
  缓存场景就用RDB，可以容许数据一定丢失，RDB对性能影响小，恢复的快 
  处理订单要用AOF，数据不容许丢失，必须用AOF
  也可以RDB+AOF混合(支付订单)

## Redis数据恢复过程
 服务重启先找AOF文件(状态最新),找不到就用RDB，将二进制数据载入内存
 加载过程会检查文件是否损坏，损坏用专门的工具修复`Redis-check-aof`  `Redis-check-rdb`

## Redis4 混合持久化
 把内存快照直接以二进制的RDB文件保存，重写期间把命令添加到后面。

 重启先加载RDB文件再执行AOF命令,既有效率又保证数据完整性
### 配置混合持久化
 ```Redis
  # 启用AOF
    appendonly yes

    # 使用混合持久化
    aof-use-rdb-preamble yes

    # 每秒同步一次AOF，平衡性能和安全性
    appendfsync everysec

    # AOF重写触发条件：文件增长100%且至少达到64MB
    auto-aof-rewrite-percentage 100
    auto-aof-rewrite-min-size 64mb

    # RDB备份策略
    save 900 1    # 15分钟内有1个修改
    save 300 10   # 5分钟内有10个修改
    save 60 10000 # 1分钟内有10000个修改 
    ```

### 如果仅使用RDB
```reids
    # 禁用AOF
    appendonly no

    # 较宽松的RDB策略
    save 3600 1    # 1小时内有1个修改
    save 300 100   # 5分钟内有100个修改
```
### AOF始终开启fsync(高一致性)
  ```redis
    appendonly yes
    # 启用AOF

    # 使用混合持久化
    aof-use-rdb-preamble yes

    # 每个命令都同步（谨慎使用，性能影响大）
    # 通常我会在关键时间窗口动态修改为always
    appendfsync always

    # 更频繁的RDB快照
    save 300 1     # 5分钟内有1个修改
    save 60 100    # 1分钟内有100个修改
  ```

### 高并发和大型实例要优化AOF重写
```redis
    # AOF重写期间不fsync，AOF 重写期间，主进程不会对新写入的 AOF 缓冲区执行 fsync 操作（即不强制刷盘），而是等重写结束后再统一刷盘。
    no-appendfsync-on-rewrite yes
    # RDB 快照保存时采用增量 fsync，即每写入一定量的数据就执行一次 fsync，将数据分批同步到磁盘。
    rdb-save-incremental-fsync yes
```

# 高可用

## 主从复制是什么
 允许从节点维护主节点数据副本,一个主节点可连接多个从节点.
 主节点负责写操作,从节点同步主节点数据变更，并处理读操作，实现读写分离

### 作用
 1. 主从分离从而读写分离，提高并发能力
 2. 从节点备份数据可以实现故障转移，提高系统的可用性

### 主从同步失败的情况？
  > [!NOTE]
  > 根本原因是异步操作和网络传输
 - 从节点同步是异步的，主节点通过网络向从从节点发送命令(写操作),如果没推送完宕机,那么旧不同步
 - 主节点内存压力大，使用了淘汰策略，从节点未及时同步导致,从节点有主节点不存在的数据

### 主从不一致的解决？
 1. 主从节点在同一网络中，避免网络延迟 
 2. 主节点的复制缓冲区容量和存活时间提高
 3. 监控和自动修复机制，定期检查主从一致性。偏移量过大就剔除从节点并全量同步

## Redis 的拓扑结构？
 一主一从，一主多从 => 树结构

## 主从复制原理？
 异步将主节点数据同步到从节点。过程是建立连接、同步数据和传播命令
 1. 建立连接：从节点执行`replicaof`连接到主，发送`psync`请求同步,主节点向该从节点建立一个连接和复制buffer
 2. 同步数据：从节点首次连接触发全量同步。主节点fork一个子线程生成RDB文件，把生成期间的命令缓存到buffer里面，
  把RDB发给从节点。从节点清空数据并加载RDB，RDB传输完成后主节点把buffer命令发给从节点
 3. 传播命令： 把每次的写命令事实发送和主节点相连的从节点
 > [!NOTE]
 > redis 2.8后把命令暂存在复制积压缓存区，供从节点重新连接后同步数据
    增量同步时把命令暂存到复制积压缓冲区，重连时同步尚未复制的命令
 
## 全量同步和增量同步？
 全量同步发送在从节点第一次连接和主节点降级为从节点并连接新的主节点上时
 
 1. 从向主发送`psync ? -1` 不知道主节点id和偏移值。主收到后回复FullReSync(全部重新同步),包含id和复制偏移值offset
 2. 主fork子线程生成RDB文件，并把期间命令存到buffer(复制缓冲区)。。。
 ==全量同步代价高，RDB文件生成和传输占用大量CPU和IO资源，网络传输还消耗带宽==
 
 为了解决全量同步问题，2.8引入了增量同步概念
 1. 从节点向主节点发送`psync <id> <offset>` 主节点查验id和偏移值，如果id不对就说明主节点发生过变化。
 2. 主节点根据offset之后的数据还在不在复制积压缓冲区，在就增量同步。不再就说明断线时间过长，操作已经覆盖了缓冲区，需要全量同步

 ==增量同步减少了带宽消耗量，减少主从节点的负载，提高了同步效率==
 唯一的限制就是网络问题，如果网络环境不稳定就要增大缓冲区的大小和存活时间
  ```redis-conf
  repl-backlog-size：1mb //积压缓冲区是个队列,默认1mb
  repl-backlog-ttl： 3600 //存活时间
```
## 主从复制的缺陷？
 1. 异步问题  , 发送过程断联。
 2. 全量同步的冲击,大量消耗CPU和IO。

 ### 脑裂问题？
  存在于哨兵架构中，哨兵会因为主节点和哨兵、从节点断联时间过长，哨兵判断下线。选出新的主节点。
  如果这个时候==原主节点没有和客户端断开连接==，就会有“两个主节点”提供服务。
  
  等到网络服务正常后，主节点发现了对方，原来的主节点自动降级并全量同步,清空原来的数据，导致数据的完整性损失
  防止数据丢失，Redis提供 参数设置
  ```redis
    #主节点进行数据同步的最小从节点数
    min-slaves-to-write  1
    #主从通信从节点发送ACK消息的最大延迟(秒)
    min-slaves-max-log  10

```
  > [!NOTE]
  > 解决主从节点断联问题就行,让主节点强行和从节点同步并且限制延迟,防止因为较大的网络延迟被判定离线 
  > 只要达不到参数要求，原主节点就拒接写入。哨兵会协商新的主节点，原来的主节点自动降级并全量同步。没有数据丢失

## Redis哨兵机制(故障转移)
 监控主从集群的状态，并进行故障转移

 ==过程==：
 一个哨兵判定主节点下线后询问其他哨兵的意见，达到配置的法定人数就会集体判断下线
 他们会选出一个领导，领导在从节点中选一个适合的。
 确定主节点后向他发送`slaveof no one `升级主节点，给其他从节点发`slaveof `命令指向新的主节点
 通过发布订阅机制通知客户端主节点发送了变化
 
### 领导选举(权威认定)
 Raft 算法
 1. 当一个哨兵判断下线后，询问其他哨兵并申请成为领导,并投自己一票
 2. 其他哨兵对主节点状态进行判断，如果候选者的日志和自己一样新，任期号比自己小，且之前没有投票过，就会同意
 3. 候选者统计自己的票数吗，如果获得了超过半数的选票，就会当领导
 4. 当不成领导就会进入下一次选举

  > [!NOTE]
  > 每个哨兵都有自己的选举时间，0~2000ms随机。在这个时间之后开始选举，减少选举冲突

### 新的主节点如何选出(最优副本)
  领导剔除不稳定和下线的从节点和优先级为0的从节点
  根据优先级，偏移量的大小(越大越新要最新),和runid的字典序(越小越优先)
  然后向该从节点发送`slaveof no one`命令升级(更新为权威数据源)，发送info检验是否升级完毕，并通知从节点更新主节点

## Redis集群
 解决Redis单机的内存限制  

 去中心化，p2p模式没有中心节点。每个节点保存数据和整个集群的状态，节点之间采用gossip协议交换信息

 集群用hash槽机制把集群划分成16384个单元，计算hash槽编号时，先用crc算法计算hash值，然后取模并分配到对应的节点

### 集群分区
 节点取余，一致性hash，hash槽

 * 节点取余:计算hash值，对已有的节点数取余，结果就是目标节点的索引
 * 一致性hash：节点区域的话改变节点数，所有的取余结果都要变，导致大部分数据失效。通过把数据抽象到环上，顺时针的下一个节点就是他的节点。
   这样集群扩容的时候，可以变动一部分数据。但是数据分布不均，有的大有的小
 * 哈希槽：把数据分配到16384个槽上，这样不用数据本体只需要重新分配他们的容器到节点上就可以了。

### Redis 集群原理
 每个节点通过设置`cluster-enable yes`设置集群模式，并`cluster meet`命令握手，把对方添加到节点列表中。

 ==详细过程(乒乓响应)==：
1. 节点1向节点2发送`cluster meet`，2回复pong发送ping给1，1回复pong 双方建立通信链路
 gossip协议中节点只需要向一部分邻居通信就可以找到自己的位置，做到了去中心化。

2. 握手完成后，`cluster addslots`添加哈希槽，分配完16384个哈希槽后集群进入就绪状态
3. 每秒主节点节点都会向一些邻居节点发送ping 消息，当发现某个节点长时间未响应pong就会被判定为下线
  半数以上的主节点认为下线时就会标记为“客观”下线


 ==部署Redis集群要多少物理节点==：
  至少3主3从。(3主仲裁机制和故障转移)
  每对主从不能在一个物理机上，否则一个物理机宕机会导致一部分数据完全丢失

  所以最理想的配置是 主a+从c  主b+从a  主c+从a , 这样只会丢失一个主节点和不相关主节点的数据副本

## Redis集群的动态伸缩
 重新分配哈希槽
 
==过程==：
 1. `cluster meet`新的节点加入，使用`reshared`命令将部分哈希槽分配给新节点

 缩容是反向操作，把他的所有哈希槽分配给其他节点，`cluster forget` 从集群中移除。
 ==用户在集群的伸缩过程中的所有操作都会被重定向到正确的节点，不会有连接丢失的问题,用户体验良好==

# 缓存 
## 缓存击穿
 某个热点数据过期时,大量请求会穿过缓存访问数据库,导致数据库承受的压力变的很大
 1. 用互斥锁让第一个线程访问数据库重建缓存 , 其他的线程等待来减小数据库压力
 2. 永不过期策略 ,设置逻辑过期时间(每次都去判断是否过期,返回旧值异步启动线程更新)

## 缓存穿透
 查询的数据不在redis ,要去数据库访问(数据有可能不存在)
 1. 布隆过滤器,判断是否在集合中
 2. 缓存空值 (要设置过期时间,防止数据无法更新)

## 缓存雪崩 
 大量缓存同时失效/服务宕机,请求都跑到数据库那边了(redis炸了)
 1. 大量缓存同时过期的情况, 设置随机过期时间
 2. 服务器宕机 , 使用集群让数据在多个节点备份,自动故障转移
 3. 设计多级缓存,设置本地二级缓存, 减轻redis压力的同时可以实现redis故障时系统继续提供服务
 4. 没失效没宕机, 就是并发量过大. 采取==限流==和==降级== 

## 布隆过滤器
 内存效率很高, 而且非常快
 误判因素: 
1. 位数组m: m越小, 哈希碰撞的概率越大
2. 哈希函数数量: 哈希函数数量应在合理的区间,过多还会误判, 过少会不精确
3. 存入数量n: 存入数量越大, 哈希碰撞的几率越大

## 计数布隆过滤器
 解决布隆过滤器位数组位共享的问题, 每一位加入计数,删除仅需把计数-1 


## 缓存和数据库的一致性
 Cache Aside + TTL 
先查redis , 再查是数据库 , 为缓存设置合理的TTL , 
先更新数据库, 在更新 Redis

### 更新Mysql和Redis 策略对比
 先更新redis , redis的网络IO非常快, 不能保证并发执行的顺序. 他会过期,和数据库不一致最终信赖的还是数据库
  导致数据回滚 
 ==代价是数据丢失==

 先删除Redis ,再更新Mysql: 一段时间内mysql没更新成功, redis被删除,会导致缓存穿透
 ==代价时缓存穿透==
 
 先更新mysql 再删除缓存: 删除缓存比更新缓存要快, 而且再MySQL没有更新成功时访问的缓存时旧数据吗,不会缓存穿透
    更新完MySQL后 删除缓存再重建, 比仅更新缓存快得多
 ==代价仅为更新mysql读到旧数据==

### 高一致性场景如何做
 支付系统, 库存管理系统 常见

1. 使用消息队列 , 更新数据库的事务提交同时发送异步消息 删除缓存保证缓存删除
  删除失败会触发重新删除
2. 使用Canal 监听 MySQL的BinLog . 一旦发生了数据更新就把数据变更记录发送给MQ, 非业务服务监听这个消息去删除redis
  删除失败都会触发重新删除

3. 简单业务可以使用延迟删
    ``redis
    delete redis(因为高一致性不能读到脏数据,强制删除过期数据)
    update db
    delete redis(第一次尝试删除)
    sleep(50)
    delete redis(再次删除确保删除成功)
    `` 
  延迟双闪要顾及合理的TTL , 保证就算最后的删除失败也要让TTL 尽可能减小影响 

 ## 多级缓存里如何保证本地缓存和Redis一致

 通过redis 的pub/sub 机制像所有的本地缓存实例发送缓存更新缓存通知(MQ),收到后的实例立刻删除或更新缓存
 
 考虑到消息丢失的可能性,引入版本号对比 . 每次从redis中拿数据时,要拿一个版本号. 
     版本号不存在就说明Redis里的数据已经失效,强制刷新
     版本号存在但是本地缓存没了, 强制刷新
     版本号存在但是不是最新, 强制刷新
     版本号存在而且最新, 直接返回本地缓存的结果

 ==关键在于保持本地缓存和Redis里的数据同时有效, 有版本号就说明Redis的还有效, 版本号最新就说明本地缓存
  和Redis同步==

## 二级缓存设计
 二级缓存设计成统一的组件, 提供一个CacheManager接口和基本操作
 
 二级缓存适合存 接受短暂不一致的数据,


## 热点key
 对于一些热点访问的场景, 有一些key同时被非常多的请求访问
 key过期删除就要接收缓存击穿的命运
所以要针对热点key 进行监控, 防止过期和及时更新

 
